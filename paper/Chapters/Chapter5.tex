\chapter{Experiments}\label{cha:experiments}

\section{Simulator}\label{sec:simulator}

We created a symulator to generate distorted points as described in
\cref{sub:complete_projection_and_backprojection}. We used it to test the
solver, and test the correctness of projection and back-projection points.

\section{Metrics}\label{sec:metrics}

\begin{itemize}
	\item Reprojection error
	\item Number of detected corners
\end{itemize}

\section{Dataset}\label{sec:dataset}

For the project, we need highly distorted photos of calibration boards. It takes
a lot of work to generate such a dataset, as cameras which produce such images are
usually expensive. Therefore, it would be preferable to use an existing dataset.

For this project, we required a highly distorted dataset of chessboard images.
We collected a number of datasets, but the feature detector we used supports
detecting only the boards with the constant tile size, therefore we cannot use
AprilGrid nor CharuCO boards. The feature detector is the only limiting factor.

\textcite{lochmanBabelCalibUniversalApproach2021} collected a wide number of
datasets, typically used in the field for the benchmarking of the camera
calibration. They're provided in a Deltille \cite{DeltilleDetector2023} format,
and are well documented:

\textbf{Kalibr} \citep{mayeSelfsupervisedCalibrationRobotic2013} contains several established datasets that are commonly used for testing
the accuracy of camera calibration frameworks: Double Sphere
\cite{usenkoDoubleSphereCamera2018}, EuRoC \cite{burriEuRoCMicroAerial2016}, TUM
VI \cite{schubertTUMVIBenchmark2018}, and ENTANIYA 1
\cite{Calibration250degFisheye}.
The Kalibr calibration framework was used in the
original publications cited above, hence the name of the dataset.
As a calibration pattern, AprilGrid with 6x6 tags of 88 mm size was used.
In total, the datasets contain approximately 800 images.

\textbf{OCamCalib} \citep{scaramuzzaFlexibleTechniqueAccurate2006} is a dataset
of approximately 300 images.
As a calibration pattern, the checkerboard pattern of different sizes was used.

\textbf{UZH} \citep{AreWeReady} is a dataset of approximately 800 images
collected using the following cameras:
As a calibration pattern, AprilGrid with 4x5 tags of 75 mm size was used.
The dataset contains approximately 800 images.

\textbf{OV} \citep{lochmanBabelCalibUniversalApproach2021} is a dataset of
approximately 1400 images. It was collected using eight stereo cameras.
As a calibration pattern, the checkerboard pattern with 9x6 tags of 22 mm size
was used.

\textcite{duisterhofTartanCalibIterativeWideAngle2022} also provide their
dataset from the TartanCalib project. Currently, the dataset contains only
AprilGrid patterns, as the toolchain doesn't support chessboard.

\begin{figure}[h]
	\centering
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth]{Kalibr.png}
		\caption{Kalibr}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth]{OCamCalib.png}
		\caption{\textbf{OCamCalib}}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth]{OV.png}
		\caption{\textbf{OV}}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth]{UZH.png}
		\caption{UZH}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\linewidth}
		\includegraphics[width=\linewidth]{tartancalib.png}
		\caption{TartanCalib}
	\end{subfigure}
	\caption{Images from the datasets}
\end{figure}

\section{Camera calibration}\label{sec:camera_calibration}

\begin{minipage}{0.5\linewidth}
	In order to get accurate predictions for the possibly missing points, we need
	very accurate camera calibration. We used the reprojection error as a metric
	for the calibration quality.
	In order to calculate the reprojection error, we have to perform the
	rootfinding \cref{subsub:back_projection_using_the_division_model}. We assume
	that all of the points lay within the image, or they get out of the borders
	a little bit (we use the constant \(1.1\) of the maximum radius). If the
	camera calibration is poor, the rootfinding might fail. On the initial
	calibration the number of the failed rootfindings was much higher.
\end{minipage}
\hfill
\begin{minipage}{0.4\linewidth}
	\resizebox{\linewidth}{!}{
		\begin{tikzpicture}
			\pie[rotate=90, explode=0.1, sum=auto, color={green!60, blue!60, red!60}, text=legend]{
				115/Correctly detected,
				80/Reprojection error > 10,
				254/Not correctly detected
			}
		\end{tikzpicture}
	}
	\captionsetup{width=.9\linewidth}
	\captionof{figure}{Initial calibration}
	\resizebox{\linewidth}{!}{
		\begin{tikzpicture}
			\pie[rotate=90, explode=0.1, sum=auto, color={green!60, blue!60, red!60}, text=legend]{
				658/Correctly detected,
				19/Reprojection error > 10,
				115/Not correctly detected
			}
		\end{tikzpicture}
	}
	\captionsetup{width=.9\linewidth}
	\captionof{figure}{Final calibration}
\end{minipage}

\begin{figure}[h]
	\begin{tikzpicture}
		\begin{axis}[
				ybar interval,
				ymin=0,
				ylabel={Frequency},
				xlabel={Value},
				height=0.3\linewidth,
				width=\linewidth,
				ticklabel style = {font=\tiny},
				% title={Initial calibration}
			]
			\addplot+ [hist={data min=0,data max=10,bins=20}] table [y index=0]
				% \addplot+ [hist={bins=30}] table [y index=0]
				{data/reprojection_error_init.txt};
		\end{axis}
	\end{tikzpicture}
	\caption{Initial calibration's reprojection error histogram}
\end{figure}
\begin{figure}[h]
	\begin{tikzpicture}
		\begin{axis}[
				ybar interval,
				ymin=0,
				ylabel={Frequency},
				xlabel={Value},
				height=0.3\linewidth,
				width=\linewidth,
				ticklabel style = {font=\tiny},
				% title={Reprojection error}
			]
			\addplot+ [hist={data min=0,data max=10,bins=20}] table [y index=0]
				% \addplot+ [hist={bins=30}] table [y index=0]
				{data/reprojection_error_final.txt};
		\end{axis}
	\end{tikzpicture}
	\caption{Final calibration's reprojection error histogram}
\end{figure}

\section{Additional features detection}\label{sec:additional_features_detection}

As discussed in \cref{sec:additional_features_detection}, we filled the gaps in
the originally detected board points, and then padded it for 1 additional
element.

\begin{figure}[h]
	\centering
	\begin{minipage}{0.55\linewidth}
		\begin{subfigure}[b]{\linewidth}
			\includegraphics[width=\linewidth]{extended_board_img.png}
			\label{fig:extended_board_img}
			\caption{Extended board, new points are marked as blue}
		\end{subfigure}
	\end{minipage}
	\begin{minipage}{0.35\linewidth}
		\resizebox{\linewidth}{!}{
			\begin{tikzpicture}
				\begin{axis}[
						xlabel={$x$},
						ylabel={$y$},
						grid=major,
						title={Original board},
					]
					\addplot[
						only marks,
					] table {data/original_board.txt};
				\end{axis}
			\end{tikzpicture}
		}
		\vfill
		\resizebox{\linewidth}{!}{
			\centering
			\begin{tikzpicture}
				\begin{axis}[
						xlabel={$x$},
						ylabel={$y$},
						grid=major,
						title={Extended board},
					]
					\addplot[
						only marks,
					] table {data/extended_board.txt};
				\end{axis}
			\end{tikzpicture}
		}
	\end{minipage}
	\caption{Board extension}
\end{figure}

\section{Classification}\label{sec:classification}

\begin{minipage}[t]{0.3\linewidth}
	We compared both responses, as discussed in \cref{sec:classifier}.
	The Hessian proved to be more robust. The approach, proposed by
	\cite{geigerAutomaticCameraRange2012} gave too many false positives,
	especially for the edges.
\end{minipage}
\hfill
\begin{minipage}[t]{0.6\linewidth}
	\includegraphics[width=\linewidth]{response_hessian.png}
	\captionof{figure}{Hessian response}
	\includegraphics[width=\linewidth]{response_other.png}
	\captionof{figure}{Response used by \cite{geigerAutomaticCameraRange2012}}
	% \end{figure}
\end{minipage}

\begin{figure}
	\centering
	\begin{subfigure}[t]{\linewidth}
		\includegraphics[width=\linewidth]{hist_response_hessian.png}
		\caption{Histogram of Hessian response}
	\end{subfigure}
	\begin{subfigure}[t]{\linewidth}
		\includegraphics[width=\linewidth]{hist_response_other.png}
		\caption{Histogram of response used by \cite{geigerAutomaticCameraRange2012}}
	\end{subfigure}
	\caption{Distributions of the responses for the image on the
		\cref{fig:extended_board_img}. Note the log y-scale! Most of the points have
		the response 0.}
\end{figure}

\section{Evaluation}\label{sec:evaluation}

\missingfigure{Compare the number of points with the provided by babelcalib}
\missingfigure{Compare the reprojection error}


